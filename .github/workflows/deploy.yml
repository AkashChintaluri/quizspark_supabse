name: Full Stack Deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: ap-south-1
  EC2_IP: "13.127.72.180"
  EC2_DNS: "ec2-13-127-72-180.ap-south-1.compute.amazonaws.com"
  ECR_REPOSITORY: "quizspark-backend"
  S3_BUCKET: "quizspark"

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: |
        npm install --save-dev eslint eslint-plugin-security eslint-plugin-sonarjs @typescript-eslint/parser @typescript-eslint/eslint-plugin

    - name: Run ESLint with security checks
      run: |
        npx eslint . --ext .js,.jsx,.ts,.tsx --config .eslintrc.json

    - name: Initialize CodeQL
      uses: github/codeql-action/init@v2
      with:
        languages: javascript

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v2

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'table'
        exit-code: '1'
        ignore-unfixed: true
        severity: 'CRITICAL,HIGH'

  monitoring-setup:
    needs: security-scan
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup monitoring infrastructure
      run: |
        # Create monitoring directory
        mkdir -p monitoring
        
        # Create Prometheus config
        cat > monitoring/prometheus.yml << EOF
        global:
          scrape_interval: 15s
          evaluation_interval: 15s

        scrape_configs:
          - job_name: 'quizspark-backend'
            static_configs:
              - targets: ['${{ env.EC2_DNS }}:3000']
          - job_name: 'node-exporter'
            static_configs:
              - targets: ['${{ env.EC2_DNS }}:9100']
        EOF

        # Create Grafana dashboard config
        cat > monitoring/grafana-dashboard.json << EOF
        {
          "dashboard": {
            "id": null,
            "title": "QuizSpark Metrics",
            "tags": ["quizspark"],
            "timezone": "browser",
            "panels": [
              {
                "title": "API Response Time",
                "type": "graph",
                "datasource": "Prometheus",
                "targets": [
                  {
                    "expr": "rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])"
                  }
                ]
              }
            ]
          }
        }
        EOF

        # Upload monitoring config to S3
        aws s3 cp monitoring/prometheus.yml s3://${{ env.S3_BUCKET }}-monitoring/prometheus.yml
        aws s3 cp monitoring/grafana-dashboard.json s3://${{ env.S3_BUCKET }}-monitoring/grafana-dashboard.json

    - name: Deploy monitoring stack
      run: |
        # SSH into EC2 and setup monitoring
        printf "%s\n" "${{ secrets.EC2_SSH_KEY }}" > key.pem
        chmod 600 key.pem
        
        ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@${{ env.EC2_IP }} << EOF
          # Install Docker Compose if not present
          sudo apt-get update
          sudo apt-get install -y docker-compose

          # Create monitoring directory
          mkdir -p ~/monitoring

          # Create docker-compose.yml for monitoring stack
          cat > ~/monitoring/docker-compose.yml << 'EOL'
          version: '3'
          services:
            prometheus:
              image: prom/prometheus:latest
              ports:
                - "9090:9090"
              volumes:
                - ./prometheus.yml:/etc/prometheus/prometheus.yml
              command:
                - '--config.file=/etc/prometheus/prometheus.yml'

            grafana:
              image: grafana/grafana:latest
              ports:
                - "3001:3000"
              environment:
                - GF_SECURITY_ADMIN_PASSWORD=${{ secrets.GRAFANA_ADMIN_PASSWORD }}
              volumes:
                - grafana-storage:/var/lib/grafana

            node-exporter:
              image: prom/node-exporter:latest
              ports:
                - "9100:9100"

            elasticsearch:
              image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
              environment:
                - discovery.type=single-node
                - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
              ports:
                - "9200:9200"
              volumes:
                - elasticsearch-data:/usr/share/elasticsearch/data

            kibana:
              image: docker.elastic.co/kibana/kibana:7.17.0
              ports:
                - "5601:5601"
              environment:
                - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

            logstash:
              image: docker.elastic.co/logstash/logstash:7.17.0
              volumes:
                - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
              ports:
                - "5000:5000"

          volumes:
            grafana-storage:
            elasticsearch-data:
          EOL

          # Create Logstash config
          cat > ~/monitoring/logstash.conf << 'EOL'
          input {
            tcp {
              port => 5000
              codec => json
            }
          }
          output {
            elasticsearch {
              hosts => ["elasticsearch:9200"]
              index => "quizspark-logs-%{+YYYY.MM.dd}"
            }
          }
          EOL

          # Download monitoring config from S3
          aws s3 cp s3://${{ env.S3_BUCKET }}-monitoring/prometheus.yml ~/monitoring/prometheus.yml
          aws s3 cp s3://${{ env.S3_BUCKET }}-monitoring/grafana-dashboard.json ~/monitoring/grafana-dashboard.json

          # Start monitoring stack
          cd ~/monitoring
          docker-compose up -d

          # Wait for services to start
          sleep 30

          # Import Grafana dashboard
          curl -X POST \
            -H "Content-Type: application/json" \
            -d @grafana-dashboard.json \
            http://admin:${{ secrets.GRAFANA_ADMIN_PASSWORD }}@localhost:3001/api/dashboards/db
        EOF

        # Clean up
        rm -f key.pem

  deploy-backend:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_ENV

    - name: Deploy to EC2
      run: |
        # Create SSH key from secret
        printf "%s\n" "${{ secrets.EC2_SSH_KEY }}" > key.pem
        chmod 600 key.pem
        if [ ! -s key.pem ]; then
          echo "Error: SSH key file is empty or not created"
          exit 1
        fi

        # SSH into EC2 and run deployment commands
        ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@${{ env.EC2_IP }} << EOF
          # Login to ECR
          aws ecr get-login-password --region ap-south-1 | docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}
          
          # Stop and remove existing container
          docker stop quizspark-backend || true
          docker rm quizspark-backend || true
          
          # Remove existing image
          docker rmi quizspark-backend || true
          
          # Pull and run new image
          docker pull ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}
          docker run -d \
            --name quizspark-backend \
            --restart unless-stopped \
            -p 3000:3000 \
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}
          
          # Wait for container to start
          sleep 10
          
          # Verify container is running
          if ! docker ps | grep -q quizspark-backend; then
            echo "Error: Container failed to start"
            docker logs quizspark-backend
            exit 1
          fi
          
          # Check container logs
          echo "Container logs:"
          docker logs quizspark-backend
        EOF
        
        # Clean up local files
        rm -f key.pem

    - name: Verify Backend Deployment
      run: |
        sleep 10
        response=$(curl -s -o /dev/null -w "%{http_code}" http://${{ env.EC2_DNS }}:3000/api/upcoming-quizzes/1)
        if [ "$response" != "200" ]; then
          echo "Error: Backend is not responding correctly"
          exit 1
        fi

    - name: Output Backend URL
      run: |
        echo "Backend deployed at: http://${{ env.EC2_DNS }}:3000"

  deploy-frontend:
    needs: deploy-backend
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build frontend
      run: npm run build

    - name: Configure S3 bucket
      run: |
        # Enable static website hosting
        aws s3api put-bucket-website \
          --bucket ${{ env.S3_BUCKET }} \
          --website-configuration '{
            "IndexDocument": {"Suffix": "index.html"},
            "ErrorDocument": {"Key": "index.html"}
          }'

        # Set bucket policy for public access
        aws s3api put-bucket-policy \
          --bucket ${{ env.S3_BUCKET }} \
          --policy '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Sid": "PublicReadGetObject",
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": "arn:aws:s3:::'${{ env.S3_BUCKET }}'/*"
              }
            ]
          }'

        # Configure CORS
        aws s3api put-bucket-cors \
          --bucket ${{ env.S3_BUCKET }} \
          --cors-configuration '{
            "CORSRules": [
              {
                "AllowedHeaders": ["*"],
                "AllowedMethods": ["GET", "HEAD"],
                "AllowedOrigins": ["*"],
                "ExposeHeaders": []
              }
            ]
          }'

    - name: Upload to S3
      run: |
        # Upload all files from dist directory
        aws s3 sync dist/ s3://${{ env.S3_BUCKET }}/
        
        # Set proper content types
        aws s3 cp s3://${{ env.S3_BUCKET }}/index.html s3://${{ env.S3_BUCKET }}/index.html --content-type "text/html" --cache-control "no-cache"
        aws s3 cp s3://${{ env.S3_BUCKET }}/assets/ s3://${{ env.S3_BUCKET }}/assets/ --recursive --content-type "application/javascript" --cache-control "public, max-age=31536000"
        aws s3 cp s3://${{ env.S3_BUCKET }}/assets/ s3://${{ env.S3_BUCKET }}/assets/ --recursive --exclude "*" --include "*.css" --content-type "text/css" --cache-control "public, max-age=31536000"
        aws s3 cp s3://${{ env.S3_BUCKET }}/assets/ s3://${{ env.S3_BUCKET }}/assets/ --recursive --exclude "*" --include "*.png" --include "*.jpg" --include "*.jpeg" --include "*.gif" --include "*.svg" --content-type "image/*" --cache-control "public, max-age=31536000"

    - name: Output Frontend URL
      run: |
        echo "Frontend deployed at: http://${{ env.S3_BUCKET }}.s3-website.${{ env.AWS_REGION }}.amazonaws.com"

        